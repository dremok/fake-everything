{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE PyTorch with Fruits.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo_svK_vX9qm",
        "colab_type": "code",
        "outputId": "cb795460-275a-4bea-b84c-ae3d74eed609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/NVlabs/ffhq-dataset.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ffhq-dataset'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 51 (delta 0), reused 1 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guj3V5IxZwEu",
        "colab_type": "code",
        "outputId": "e9d151ff-1079-414c-be4b-5365651e0976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "!python ffhq-dataset/download_ffhq.py -t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading JSON metadata...\n",
            "| 100.00% done  2/2 files  0.25/0.25 GB   0.16 GB/s   ETA: done    \n",
            "Parsing JSON metadata...\n",
            "Downloading 70001 files...\n",
            "-   1.29% done  908/70001 files  0.03/1.96 GB   3.33 MB/s   ETA: 9m 54s  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72saW3_dFQh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as Fa\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96yOY_7QFQiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbhRC9cOFQjB",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz1alsF9FQjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 30\n",
        "log_interval = 10\n",
        "x_dim = 128\n",
        "y_dim = 128\n",
        "nb_channels = 3\n",
        "embedding_dim = 2048\n",
        "base_dir = 'thumbnails128x128'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHvJ_GlCFQjE",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyJXITMkFQjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(data_path):\n",
        "    dataset = torchvision.datasets.ImageFolder(\n",
        "        root=data_path,\n",
        "        transform=transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "    )\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=0,\n",
        "        shuffle=True\n",
        "    )\n",
        "    return data_loader\n",
        "\n",
        "train_loader = load_dataset(f'{base_dir}')\n",
        "test_loader = load_dataset(f'{base_dir}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPbP0_C3FQjW",
        "colab_type": "text"
      },
      "source": [
        "## Example image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz10SKC4fRMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_img(img):\n",
        "  plt.figure()\n",
        "  plt.imshow(img.numpy())\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-vD2cAMFQjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = next(iter(train_loader))[0][0]\n",
        "img = img.permute(1, 2, 0)\n",
        "img = img.view(img.shape[0], img.shape[1], nb_channels)\n",
        "plot_img(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU50RncKFQjg",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLSt3iZ_FQjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(x_dim*y_dim*nb_channels, embedding_dim)\n",
        "        self.fc21 = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.fc22 = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.fc3 = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.fc4 = nn.Linear(embedding_dim, x_dim*y_dim*nb_channels)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, x_dim*y_dim*nb_channels))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ldvRXrMFQjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class VAE_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE_CNN, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv31 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn31 = nn.BatchNorm2d(128)\n",
        "        self.conv32 = nn.Conv2d(128, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn32 = nn.BatchNorm2d(32)\n",
        "        self.conv4 = nn.Conv2d(32, 16, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # Latent vectors mu and sigma\n",
        "        self.fc1 = nn.Linear(32 * 32 * 16, embedding_dim)\n",
        "        self.fc_bn1 = nn.BatchNorm1d(embedding_dim)\n",
        "        self.fc21 = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.fc22 = nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "        # Sampling vector\n",
        "        self.fc3 = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.fc_bn3 = nn.BatchNorm1d(embedding_dim)\n",
        "        self.fc4 = nn.Linear(embedding_dim, 32 * 32 * 16)\n",
        "        self.fc_bn4 = nn.BatchNorm1d(32 * 32 * 16)\n",
        "\n",
        "        # Decoder\n",
        "        self.conv5 = nn.ConvTranspose2d(16, 64, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)\n",
        "        self.bn5 = nn.BatchNorm2d(64)\n",
        "        self.conv6 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn6 = nn.BatchNorm2d(32)\n",
        "        self.conv7 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False)\n",
        "        self.bn7 = nn.BatchNorm2d(16)\n",
        "        self.conv8 = nn.ConvTranspose2d(16, 3, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def encode(self, x):\n",
        "        conv1 = self.relu(self.bn1(self.conv1(x)))\n",
        "        conv2 = self.relu(self.bn2(self.conv2(conv1)))\n",
        "        conv3 = self.relu(self.bn3(self.conv3(conv2)))\n",
        "        conv31 = self.relu(self.bn31(self.conv31(conv3)))\n",
        "        conv32 = self.relu(self.bn32(self.conv32(conv31)))\n",
        "        conv4 = self.relu(self.bn4(self.conv4(conv32))).view(-1, 32 * 32 * 16)\n",
        "\n",
        "        fc1 = self.relu(self.fc_bn1(self.fc1(conv4)))\n",
        "\n",
        "        r1 = self.fc21(fc1)\n",
        "        r2 = self.fc22(fc1)\n",
        "        \n",
        "        return r1, r2\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = Variable(std.data.new(std.size()).normal_())\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    def decode(self, z):\n",
        "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
        "        fc4 = self.relu(self.fc_bn4(self.fc4(fc3))).view(-1, 16, 32, 32)\n",
        "\n",
        "        conv5 = self.relu(self.bn5(self.conv5(fc4)))\n",
        "        conv6 = self.relu(self.bn6(self.conv6(conv5)))\n",
        "        conv7 = self.relu(self.bn7(self.conv7(conv6)))\n",
        "        return self.conv8(conv7).view(-1, 3, x_dim, y_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2trE36jYFQjp",
        "colab_type": "text"
      },
      "source": [
        "### Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh8gIUAzFQjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, x_dim*y_dim*nb_channels), reduction='sum')\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return BCE + KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUJLfZPpFQj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
        "        self.bce_loss = nn.BCELoss(reduction=\"sum\")\n",
        "\n",
        "    def forward(self, x_recon, x, mu, logvar):\n",
        "        loss_rec = self.mse_loss(x_recon, x)\n",
        "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "        return loss_rec + loss_KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQXrgTAHFQjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = VAE_CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_func = CustomLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swVFSEVJFQj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_func(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa7-AwvwFQj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_func(recon_batch, data, mu, logvar).item()\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 8)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                      recon_batch.view(batch_size, nb_channels, x_dim, y_dim)[:n]])\n",
        "                os.makedirs('results', exist_ok=True)\n",
        "                save_image(comparison.cpu(),\n",
        "                         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "    return test_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXf1AfeIFQkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    all_losses = []\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(epoch)\n",
        "        test_loss = test(epoch)\n",
        "        all_losses.append(test_loss)\n",
        "\n",
        "        plt.plot(all_losses)\n",
        "        plt.ylabel('Test loss')\n",
        "        plt.show()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            sample = torch.randn(batch_size, embedding_dim).to(device)\n",
        "            sample = model.decode(sample).cpu()\n",
        "            filename = 'results/sample_' + str(epoch) + '.png'\n",
        "            save_image(sample.view(batch_size, nb_channels, x_dim, y_dim), filename)\n",
        "            from IPython.display import Image\n",
        "            Image(f\"results/{filename}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-_L-ij_fJJ5",
        "colab_type": "code",
        "outputId": "1b2be0fc-9342-45e5-9399-565a14b10fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!ls results/"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reconstruction_10.png  reconstruction_5.png  sample_10.png  sample_5.png\n",
            "reconstruction_1.png   reconstruction_6.png  sample_1.png   sample_6.png\n",
            "reconstruction_2.png   reconstruction_7.png  sample_2.png   sample_7.png\n",
            "reconstruction_3.png   reconstruction_8.png  sample_3.png   sample_8.png\n",
            "reconstruction_4.png   reconstruction_9.png  sample_4.png   sample_9.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeu8IPD9sXG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(f\"results/sample_10.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpaYwhxQsary",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}